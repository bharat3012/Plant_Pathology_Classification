{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-13T09:43:39.795546Z",
     "iopub.status.busy": "2021-07-13T09:43:39.795204Z",
     "iopub.status.idle": "2021-07-13T09:43:44.124241Z",
     "shell.execute_reply": "2021-07-13T09:43:44.123427Z",
     "shell.execute_reply.started": "2021-07-13T09:43:39.795470Z"
    },
    "id": "T7NMYav9mHHL"
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# Neural networks can be constructed using the torch.nn package.\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "#from pytorch_lightning.metrics.functional import accuracy\n",
    "from collections import defaultdict\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:43:50.698536Z",
     "iopub.status.busy": "2021-07-13T09:43:50.698203Z",
     "iopub.status.idle": "2021-07-13T09:43:50.741454Z",
     "shell.execute_reply": "2021-07-13T09:43:50.740759Z",
     "shell.execute_reply.started": "2021-07-13T09:43:50.698507Z"
    },
    "id": "RdIBKOZ6mHHS",
    "outputId": "96d80998-c7a6-4496-a179-ac47afabbf91"
   },
   "outputs": [],
   "source": [
    "#read Data\n",
    "PATH='data/'\n",
    "train_data=pd.read_csv(PATH+'train.csv')\n",
    "test_data=pd.read_csv(PATH+'test.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:43:53.144574Z",
     "iopub.status.busy": "2021-07-13T09:43:53.144258Z",
     "iopub.status.idle": "2021-07-13T09:43:53.170170Z",
     "shell.execute_reply": "2021-07-13T09:43:53.169298Z",
     "shell.execute_reply.started": "2021-07-13T09:43:53.144545Z"
    },
    "id": "v4sPEXqTmHHW"
   },
   "outputs": [],
   "source": [
    "# image path  as column \n",
    "def image_(dat):\n",
    "    return PATH+'images/'+dat+'.jpg'\n",
    "\n",
    "train_data['image_path']=train_data[[\"image_id\"]].apply(image_)\n",
    "test_data['image_path']=test_data[[\"image_id\"]].apply(image_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:43:56.548609Z",
     "iopub.status.busy": "2021-07-13T09:43:56.548294Z",
     "iopub.status.idle": "2021-07-13T09:43:56.555111Z",
     "shell.execute_reply": "2021-07-13T09:43:56.554269Z",
     "shell.execute_reply.started": "2021-07-13T09:43:56.548580Z"
    },
    "id": "UwsJQPzgmHHY"
   },
   "outputs": [],
   "source": [
    "#apply albumenation for transformation\n",
    "train_transform =  A.Compose([\n",
    " A.SmallestMaxSize(max_size=160),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.RandomCrop(height=128, width=128),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "Val_transform=transforms.Compose([\n",
    "        A.SmallestMaxSize(max_size=160),\n",
    "        A.CenterCrop(height=128, width=128),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:43:59.232724Z",
     "iopub.status.busy": "2021-07-13T09:43:59.232392Z",
     "iopub.status.idle": "2021-07-13T09:43:59.240099Z",
     "shell.execute_reply": "2021-07-13T09:43:59.239321Z",
     "shell.execute_reply.started": "2021-07-13T09:43:59.232674Z"
    },
    "id": "1URiZvCfmHHa"
   },
   "outputs": [],
   "source": [
    "#splitting data as train and test \n",
    "validation_split = .3\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "\n",
    "# tr, val = train_test_split(data.label, stratify=data.label, test_size=0.1)\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:10.434139Z",
     "iopub.status.busy": "2021-07-13T09:44:10.433791Z",
     "iopub.status.idle": "2021-07-13T09:44:10.438250Z",
     "shell.execute_reply": "2021-07-13T09:44:10.437319Z",
     "shell.execute_reply.started": "2021-07-13T09:44:10.434107Z"
    },
    "id": "4mR5gl97mHHc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Creating  data samplers:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:12.245758Z",
     "iopub.status.busy": "2021-07-13T09:44:12.245386Z",
     "iopub.status.idle": "2021-07-13T09:44:12.251826Z",
     "shell.execute_reply": "2021-07-13T09:44:12.250933Z",
     "shell.execute_reply.started": "2021-07-13T09:44:12.245725Z"
    },
    "id": "N23SBpP7mHHd"
   },
   "outputs": [],
   "source": [
    "names=train_data.iloc[:,1:-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:13.909760Z",
     "iopub.status.busy": "2021-07-13T09:44:13.909412Z",
     "iopub.status.idle": "2021-07-13T09:44:13.916258Z",
     "shell.execute_reply": "2021-07-13T09:44:13.915406Z",
     "shell.execute_reply.started": "2021-07-13T09:44:13.909725Z"
    },
    "id": "dHDaDat9mHHe"
   },
   "outputs": [],
   "source": [
    "class plant_data(Dataset):\n",
    "    def __init__(self,data,transform=None):\n",
    "        self.data=data\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image=cv2.imread(self.data.loc[index,'image_path'])\n",
    "        image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label=torch.tensor(self.data.loc[index,names])\n",
    "        if self.transform is not None:\n",
    "              image = self.transform(image=image)[\"image\"]\n",
    "    \n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:15.921468Z",
     "iopub.status.busy": "2021-07-13T09:44:15.921157Z",
     "iopub.status.idle": "2021-07-13T09:44:15.969636Z",
     "shell.execute_reply": "2021-07-13T09:44:15.968839Z",
     "shell.execute_reply.started": "2021-07-13T09:44:15.921439Z"
    },
    "id": "2xL7ZuN0mHHg",
    "outputId": "3af88524-f465-4351-9e34-96c572dc54ea"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:31.206510Z",
     "iopub.status.busy": "2021-07-13T09:44:31.206193Z",
     "iopub.status.idle": "2021-07-13T09:44:31.211944Z",
     "shell.execute_reply": "2021-07-13T09:44:31.210022Z",
     "shell.execute_reply.started": "2021-07-13T09:44:31.206479Z"
    },
    "id": "4vpRZ9F2mHHi"
   },
   "outputs": [],
   "source": [
    "tran_dataset = plant_data(train_data,transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:32.649654Z",
     "iopub.status.busy": "2021-07-13T09:44:32.649342Z",
     "iopub.status.idle": "2021-07-13T09:44:32.654185Z",
     "shell.execute_reply": "2021-07-13T09:44:32.653175Z",
     "shell.execute_reply.started": "2021-07-13T09:44:32.649625Z"
    },
    "id": "Mkg4ua2-mHHk"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(tran_dataset, batch_size=16,  sampler=train_sampler)\n",
    "valid_loader= torch.utils.data.DataLoader(tran_dataset, batch_size=16,  sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:34.081788Z",
     "iopub.status.busy": "2021-07-13T09:44:34.081440Z",
     "iopub.status.idle": "2021-07-13T09:44:34.088160Z",
     "shell.execute_reply": "2021-07-13T09:44:34.087310Z",
     "shell.execute_reply.started": "2021-07-13T09:44:34.081740Z"
    },
    "id": "YKssiZm1mHHl"
   },
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, idx=0, samples=10, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(samples):\n",
    "        image, _ = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:35.570001Z",
     "iopub.status.busy": "2021-07-13T09:44:35.569478Z",
     "iopub.status.idle": "2021-07-13T09:44:36.699213Z",
     "shell.execute_reply": "2021-07-13T09:44:36.698175Z",
     "shell.execute_reply.started": "2021-07-13T09:44:35.569954Z"
    },
    "id": "Dt6LLn38mHHm",
    "outputId": "34e59160-7589-4462-e114-86eeaabb7c65"
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "visualize_augmentations(tran_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:37.810386Z",
     "iopub.status.busy": "2021-07-13T09:44:37.810038Z",
     "iopub.status.idle": "2021-07-13T09:44:37.816418Z",
     "shell.execute_reply": "2021-07-13T09:44:37.815440Z",
     "shell.execute_reply.started": "2021-07-13T09:44:37.810355Z"
    },
    "id": "TwRQZbe9mHHo",
    "outputId": "e8e5043f-3767-4a7f-da33-e5559e1c3872"
   },
   "outputs": [],
   "source": [
    "\"\"\"def calculate_accuracy(output, target):\n",
    "    output = torch.sigmoid(output) >= 0.5\n",
    "    target = target == 1.0\n",
    "    return torch.true_divide((target == output).sum(dim=1), (output.size(0)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:39.130981Z",
     "iopub.status.busy": "2021-07-13T09:44:39.130609Z",
     "iopub.status.idle": "2021-07-13T09:44:39.138696Z",
     "shell.execute_reply": "2021-07-13T09:44:39.137737Z",
     "shell.execute_reply.started": "2021-07-13T09:44:39.130949Z"
    },
    "id": "wUK6OLS4mHHp"
   },
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:40.381987Z",
     "iopub.status.busy": "2021-07-13T09:44:40.381621Z",
     "iopub.status.idle": "2021-07-13T09:44:40.387455Z",
     "shell.execute_reply": "2021-07-13T09:44:40.386637Z",
     "shell.execute_reply.started": "2021-07-13T09:44:40.381958Z"
    },
    "id": "szcfhMiJmHHq"
   },
   "outputs": [],
   "source": [
    "class DenseCrossEntropy(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self,logits,labels):\n",
    "        logits = logits.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        logprobs = F.log_softmax(logits,dim=1)\n",
    "        \n",
    "        loss =-labels*logprobs\n",
    "        loss = loss.sum(-1)\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:44:41.956702Z",
     "iopub.status.busy": "2021-07-13T09:44:41.956365Z",
     "iopub.status.idle": "2021-07-13T09:44:41.961745Z",
     "shell.execute_reply": "2021-07-13T09:44:41.960896Z",
     "shell.execute_reply.started": "2021-07-13T09:44:41.956656Z"
    },
    "id": "AfP4LDbamHHq",
    "outputId": "d93a6bc7-6de6-4b02-944b-338605421c1f"
   },
   "outputs": [],
   "source": [
    "\"\"\"params = {\n",
    "    \"model\": \"resnet50\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_workers\": 4,\n",
    "    \"epochs\": 10,\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:48:19.972921Z",
     "iopub.status.busy": "2021-07-13T09:48:19.972570Z",
     "iopub.status.idle": "2021-07-13T09:48:19.979951Z",
     "shell.execute_reply": "2021-07-13T09:48:19.979108Z",
     "shell.execute_reply.started": "2021-07-13T09:48:19.972890Z"
    },
    "id": "DM7_jhm_mHHr"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target.type_as(output))\n",
    "        #acc = calculate_accuracy(output, target.type_as(output))\n",
    "        score=f1_score(target.data.to('cpu'), output.data.to('cpu') > 0.5, average=\"samples\")\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"F1 score\", score.item())\n",
    "        #metric_monitor.update(\"Accuracy\", acc)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train: {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T10:14:27.943576Z",
     "iopub.status.busy": "2021-07-13T10:14:27.943258Z",
     "iopub.status.idle": "2021-07-13T10:14:27.951391Z",
     "shell.execute_reply": "2021-07-13T10:14:27.950523Z",
     "shell.execute_reply.started": "2021-07-13T10:14:27.943547Z"
    },
    "id": "M6nlm9v3mHHt"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    temp_score = 0\n",
    "    temp_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            output = model(images)\n",
    "            \n",
    "            loss = criterion(output, target.type_as(output))\n",
    "            #acc = calculate_accuracy(output, target.type_as(output))\n",
    "            score=f1_score(target.data.to('cpu'), output.data.to('cpu') > 0.5, average=\"samples\")\n",
    "            temp_score+=score\n",
    "            temp_loss+=loss\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"F1 score\", score.item())\n",
    "            #metric_monitor.update(\"Accuracy\", acc)\n",
    "            stream.set_description(\n",
    "            \"Epoch: {epoch}. Val: {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor,))\n",
    "    fin_score = temp_score/i\n",
    "    return fin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T10:14:33.357769Z",
     "iopub.status.busy": "2021-07-13T10:14:33.357414Z",
     "iopub.status.idle": "2021-07-13T10:14:33.674044Z",
     "shell.execute_reply": "2021-07-13T10:14:33.673058Z",
     "shell.execute_reply.started": "2021-07-13T10:14:33.357737Z"
    },
    "id": "-kcMcDJ0mHHu"
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(p=0.3),\n",
    "                        nn.Linear(512,4))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion =  nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T10:14:33.675968Z",
     "iopub.status.busy": "2021-07-13T10:14:33.675616Z",
     "iopub.status.idle": "2021-07-13T11:09:12.335728Z",
     "shell.execute_reply": "2021-07-13T11:09:12.334804Z",
     "shell.execute_reply.started": "2021-07-13T10:14:33.675933Z"
    },
    "id": "EPxO8ELtmHHv",
    "outputId": "85bc4888-fb62-423c-be26-e96c6e050f0b"
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "PATH = \"weights/chk_pt.pt\"\n",
    "for epoch in range(1, 50 + 1):\n",
    "    train(train_loader, model_ft, criterion, optimizer_ft, epoch)\n",
    "    valid_score = validate(valid_loader, model_ft, criterion, epoch)\n",
    "    if valid_score>best_score:\n",
    "        print('overwriting model, as '+str(valid_score)+' is better than '+str(best_score))\n",
    "        torch.save(model_ft.state_dict(), PATH)\n",
    "        best_score = valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:22:47.450661Z",
     "iopub.status.busy": "2021-07-13T09:22:47.450346Z",
     "iopub.status.idle": "2021-07-13T09:22:47.698676Z",
     "shell.execute_reply": "2021-07-13T09:22:47.697790Z",
     "shell.execute_reply.started": "2021-07-13T09:22:47.450632Z"
    },
    "id": "vU0A5I2AmHHw"
   },
   "outputs": [],
   "source": [
    "EPOCH = 30\n",
    "PATH = \"weights/model.pt\"\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T09:22:47.700952Z",
     "iopub.status.busy": "2021-07-13T09:22:47.700582Z",
     "iopub.status.idle": "2021-07-13T09:22:47.708962Z",
     "shell.execute_reply": "2021-07-13T09:22:47.707886Z",
     "shell.execute_reply.started": "2021-07-13T09:22:47.700916Z"
    },
    "id": "F9YjO6QxmHHx"
   },
   "outputs": [],
   "source": [
    "class plant_test_data(Dataset):\n",
    "    def __init__(self,data,transform=None):\n",
    "        self.data=data\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image=cv2.imread(self.data.loc[index,'image_path'])\n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "              image =self.transform(image=image)[\"image\"]\n",
    "    \n",
    "\n",
    "        return image\n",
    "    \n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=160),\n",
    "        A.CenterCrop(height=128, width=128),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-13T07:52:29.406105Z",
     "iopub.status.idle": "2021-07-13T07:52:29.406585Z"
    },
    "id": "_L8O5sVYmHHx"
   },
   "outputs": [],
   "source": [
    "test_dataset = plant_test_data(test_data,test_transform)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset, batch_size=1,shuffle=False, pin_memory=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-13T07:52:29.407557Z",
     "iopub.status.idle": "2021-07-13T07:52:29.408062Z"
    },
    "id": "q7XKpauomHHy"
   },
   "outputs": [],
   "source": [
    "model = model_ft.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        output = model(images)\n",
    "        #predictions = (torch.sigmoid(output) >= 0.5)[:, 0].cpu().numpy()\n",
    "        predicted_labels.append(torch.sigmoid(output).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-13T07:52:29.409068Z",
     "iopub.status.idle": "2021-07-13T07:52:29.409553Z"
    },
    "id": "YAgOnsv7mHHz"
   },
   "outputs": [],
   "source": [
    "samp=pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-13T07:52:29.410599Z",
     "iopub.status.idle": "2021-07-13T07:52:29.411429Z"
    },
    "id": "Gxfmj4VXmHH0"
   },
   "outputs": [],
   "source": [
    "final=pd.concat([samp,pd.DataFrame(np.array(predicted_labels).reshape(-1,4),columns=names)],axis=1)\n",
    "final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-13T07:52:29.412861Z",
     "iopub.status.idle": "2021-07-13T07:52:29.413399Z"
    },
    "id": "C_5tKrBjmHH0"
   },
   "outputs": [],
   "source": [
    "final.to_csv('sample_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "plant-pathology-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
